#!/usr/bin/env python
# coding: utf-8

# In[274]:


import pandas as pd 
import os
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np

data = pd.read_csv('/Users/natasha246/Documents/questions_list_users_sorted.csv', delimiter = ',')
df = pd.DataFrame(data)


# In[275]:


ind = 0
questions = []
y = []
while ind!=500: 
    questions.append(data.iloc[ind, 4])
    y.append(data.iloc[ind,9])
    ind+=1    
y = np.array(y)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(questions)


# In[276]:


import numpy as np
import csv
from gensim import corpora, models
from gensim.corpora import Dictionary
from gensim.models import ldamodel
from collections import defaultdict
import spacy
spacy.load('en')
from spacy.lang.en import English
parser = English()


# In[277]:


def tokenize(text):
    lda_tokens = []
    tokens = parser(text)
    for token in tokens:
        if token.orth_.isspace():
            continue
        else:
            lda_tokens.append(token.lower_)
    return lda_tokens


# In[278]:


y = []
ind = 0 
while ind!= 500:
    y.append(data.iloc[ind,9])
    ind+=1


# In[279]:


lol_users = defaultdict(list)

for line in csv.DictReader(open('/Users/natasha246/Documents/questions_list_users_sorted.csv')):
    lol_users[line['User']] += tokenize(line['Text'])   
text_data = lol_users.values()

dictionary = Dictionary(text_data)
corpus = [dictionary.doc2bow(text) for text in text_data]
numtop = 10
model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=numtop)


lol_ = []
tm = []
users = []
for k, v in lol_users.items():
    bow = dictionary.doc2bow(v)
    doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)
    #print(k, doc_topics) 
    users.append(k)
    arr = [0] * numtop
    for tuple in doc_topics:
        index,prob = tuple
        arr[index] = prob
    lol_.append(arr)    


# In[280]:


tm = []
counter = 0
ind = 0
for user in users:
    count = 0
    for line in csv.DictReader(open('/Users/natasha246/Documents/questions_list_users_sorted.csv')):
        if user == line['User']:
            count+=1
    i = 0
    while i!=count:
        tm.append(lol_[ind])
        i+=1
    ind +=1   


# In[281]:


matrix = np.hstack((X.toarray(), tm))


# In[284]:


from sklearn.naive_bayes import GaussianNB
model = GaussianNB()

from sklearn.model_selection import KFold 
from sklearn import metrics


kf = KFold(n_splits = 10, shuffle = True)

for train_index, test_index in kf.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = matrix[train_index], matrix[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train,y_train)
    predict = model.predict(X_test)
    print("Accuracy:", metrics.accuracy_score(y_test, predict)) 


# In[ ]:




