import pandas as pd 
import os
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np

#read csv file
data = pd.read_csv('/Users/natasha246/Documents/questions_list_users_sorted.csv', delimiter = ',')
df = pd.DataFrame(data)

#appends questions and labels into lists
ind = 0
questions = []
label = []
while ind!=500: 
    questions.append(data.iloc[ind, 4])
    label.append(data.iloc[ind,9])
    ind+=1    
label = np.array(label)
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(questions)

import csv
from gensim import corpora, models
from gensim.corpora import Dictionary
from gensim.models import ldamodel
from collections import defaultdict
import spacy
spacy.load('en')
from spacy.lang.en import English
parser = English()


#cleans text of unnecessary words for lda 
def tokenize(text):
    lda_tokens = []
    tokens = parser(text)
    for token in tokens:
        if token.orth_.isspace():
            continue
        else:
            lda_tokens.append(token.lower_)
    return lda_tokens


#create list of lists from users's tweets
lol_users = defaultdict(list)

for line in csv.DictReader(open('/Users/natasha246/Documents/questions_list_users_sorted.csv')):
    lol_users[line['User']] += tokenize(line['Text'])   
text_data = lol_users.values()

dictionary = Dictionary(text_data)
corpus = [dictionary.doc2bow(text) for text in text_data]
numtop = 10
model = ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=numtop)


lol_topics = []
users = []
for k, v in lol_users.items():
    bow = dictionary.doc2bow(v)
    doc_topics, word_topics, phi_values = model.get_document_topics(bow, per_word_topics=True)
    #print(k, doc_topics) 
    users.append(k)
    arr = [0] * numtop
    for tuple in doc_topics:
        index,prob = tuple
        arr[index] = prob
    lol_topics.append(arr)    

#makes the topic modeling features from user level to tweet level
bigmatrix_lol_topics= []
counter = 0
ind = 0
for user in users:
    count = 0
    for line in csv.DictReader(open('/Users/natasha246/Documents/questions_list_users_sorted.csv')):
        if user == line['User']:
            count+=1
    i = 0
    while i!=count:
        bigmatrix_lol_topics.append(lol_[ind])
        i+=1
    ind +=1  
    
#matrices side-by-side
matrix = np.hstack((X.toarray(), bigmatrix_lol_topics))


#Naive Bayes Classifier
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()

from sklearn.model_selection import KFold 
from sklearn import metrics


kf = KFold(n_splits = 10, shuffle = True)

for train_index, test_index in kf.split(X):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = matrix[train_index], matrix[test_index]
    y_train, y_test = label[train_index], label[test_index]
    model.fit(X_train,y_train)
    predict = model.predict(X_test)
    print("Accuracy:", metrics.accuracy_score(y_test, predict)) 
